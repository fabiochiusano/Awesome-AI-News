# NVIDIA news

| Title | Summary | Topics | Week |
| --- | --- | --- | --- |
| [Nvidia Stock Surges as Sales Forecast Delivers on AI Hopes](https://finance.yahoo.com/news/nvidia-forecast-shatters-estimates-ai-210754051.html) ğŸŸ¢ | Nvidiaâ€™s stock surged 9.3% after a promising sales forecast, pointing to a robust demand for AI technologies. The $28 billion projected Q2 revenue exceeds expectations, highlighting the companyâ€™s strong position in the AI market, buoyed by their new Blackwell chips and significant data-center revenue. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-05-27 |
| [Googleâ€™s new chips look to challenge Nvidia, Microsoft and Amazon](https://qz.com/google-ai-chip-nvidia-axion-arm-microsoft-1851397201) ğŸŸ¢ | Google has unveiled the Cloud TPU v5p, an AI chip that delivers nearly triple the training speed of its predecessor, the TPU v4, reinforcing its position in AI services and hardware. At the Google Cloud Next event, CEO Pichai highlighted the companyâ€™s AI advancements and collaborations, including the use of the A3 supercomputer and Blackwell chips in the AI Hypercomputer. Additionally, Google introduced the Google Axion CPU, an Arm-based processor that competes with similar offerings from Microsoft and Amazon, boasting a 30% performance improvement and better energy efficiency. | [Amazon ğŸŒ³](Topic_Amazon.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Google ğŸ”](Topic_Google.md), [Microsoft ğŸªŸ](Topic_Microsoft.md) | 2024-04-23 |
| [Lambda Announces $500M GPU-Backed Facility to Expand Cloud for AI](https://www.businesswire.com/news/home/20240402148086/en/Lambda-Announces-500M-GPU-Backed-Facility-to-Expand-Cloud-for-AI) ğŸŸ¢ | Lambda has successfully secured $500 million in funding to enhance its AI-oriented cloud services, powered by NVIDIA GPUs, following a Series C investment round. | [Funding ğŸ’°](Topic_Funding.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-04-08 |
| [â€˜We Created a Processor for the Generative AI Era,â€™ NVIDIA CEO Says](https://blogs.nvidia.com/blog/2024-gtc-keynote/) ğŸŸ¢ | NVIDIA CEO Jensen Huang announced the NVIDIA Blackwell computing platform at the GTC conference, aimed at advancing generative AI with superior training and inference capabilities. The platform includes enhanced interconnects for better performance and scalability. NVIDIA also launched NIM microservices for tailored AI deployment and Omniverse Cloud APIs for sophisticated simulation, signaling a transformative impact on sectors like healthcare and robotics. | [AI in healthcare ğŸ¥](Topic_AI_in_healthcare.md), [Robotics ğŸ¤–](Topic_Robotics.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-03-25 |
| [Nvidiaâ€™s data center GPU sales grow by a stunning 409% on huge demand for AI chips](https://siliconangle.com/2024/02/21/nvidias-data-center-gpu-sales-grow-stunning-409-huge-demand-ai-chips/) ğŸŸ¢ | Nvidia has experienced a significant surge in GPU sales, reporting a 409% increase due in large part to the rising demand for AI technologies. With Q4 earnings and revenue significantly outpacing Wall Street forecasts, the companyâ€™s financials have thrived on the back of robust sales from their Hopper GPU series, including the H100. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-02-26 |
| [GPU cloud company Together AI to raise $100m](https://www.datacenterdynamics.com/en/news/together-ai-set-to-receive-100m-in-funding-round-led-by-salesforce-ventures/) ğŸŸ¢ | Together AI, a GPU cloud company specializing in open-source AI tools and Nvidia server chip access, is nearing a $100 million funding round led by Salesforce Ventures, potentially elevating its valuation to $1 billion. | [Funding ğŸ’°](Topic_Funding.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-02-19 |
| [Hugging Face and Google partner for open AI collaboration](https://huggingface.co/blog/gcp-partnership) ğŸŸ¢ | Hugging Face has partnered with Google Cloud, providing users with access to enhanced AI models and integration with Google Cloud services like GKE and Vertex AI, utilizing Google TPUs and NVIDIA H100 GPUs. | [Hugging Face ğŸ¤—](Topic_Hugging_Face.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Google ğŸ”](Topic_Google.md) | 2024-01-29 |
| [Mark Zuckerberg indicates Meta is spending billions of dollars on Nvidia AI chips](https://www.cnbc.com/2024/01/18/mark-zuckerberg-indicates-meta-is-spending-billions-on-nvidia-ai-chips.html) ğŸŸ¢ | Meta plans a significant investment in AI research by integrating 350,000 Nvidia H100 GPUs by 2024. Given their high cost â€” estimated between $25K-$30K â€” this investment underlines Metaâ€™s commitment to scaling up computing power. Overall, Metaâ€™s strategy to amass the computational equivalent of 600K H100 GPUs highlights a substantial push to enhance its AI capabilities. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Meta â™¾](Topic_Meta.md) | 2024-01-22 |
| [Nvidia unveils H200, its newest high-end chip for training AI models](https://www.cnbc.com/2023/11/13/nvidia-unveils-h200-its-newest-high-end-chip-for-training-ai-models.html) ğŸŸ¢ | Nvidia introduces the H200 GPU, an upgraded version with 141GB of high-bandwidth memory. This enhancement helps with the inference process in training large AI models. Set to be released in Q2 2024, the H200 will compete with AMDâ€™s MI300X GPU, which also offers increased memory capacity for handling big models. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-11-20 |
| [NVIDIA makes Pandas much faster leveraging GPUs](https://rapids.ai/cudf-pandas/) ğŸŸ¢ | NVIDIA has significantly enhanced the Pandas library, achieving up to 150 times faster performance by capitalizing on GPUs. With the new cudf.pandas module, operations are seamlessly executed on either the GPU or CPU, providing automatic synchronization and efficient switching between the two. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-11-13 |
| [New AWS service lets customers rent Nvidia GPUs for quick AI projects](https://techcrunch.com/2023/11/01/new-aws-service-lets-customers-rent-nvidia-gpus-for-quick-ai-projects/) ğŸŸ¢ | AWS has introduced Amazon Elastic Compute Cloud (EC2) Capacity Blocks for ML, enabling AI practitioners to reserve Nvidia GPUs for specific time periods. This new service grants access to Nvidia H100 Tensor Core GPU instances, allowing users to reserve instances for up to 14 days ahead of time, with shutdowns scheduled automatically. | [Amazon ğŸŒ³](Topic_Amazon.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-11-13 |
| [New AWS service lets customers rent Nvidia GPUs for quick AI projects](https://techcrunch.com/2023/11/01/new-aws-service-lets-customers-rent-nvidia-gpus-for-quick-ai-projects/) ğŸŸ¢ | AWS launches Amazon Elastic Compute Cloud (EC2) Capacity Blocks for ML, allowing customers to rent Nvidia GPUs for specific time frames. | [Amazon ğŸŒ³](Topic_Amazon.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-11-06 |
| [Microsoft to Unveil In-House AI Chip, Reducing Reliance on NVIDIA](https://www.maginative.com/article/microsoft-to-unveil-in-house-ai-chip-reducing-reliance-on-nvidia/) ğŸ”´ | Microsoft is soon launching its own AI chip called Athena, aiming to reduce reliance on NVIDIA GPUs and compete against NVIDIAâ€™s H100 GPU for AI acceleration in data centers. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Microsoft ğŸªŸ](Topic_Microsoft.md) | 2023-10-10 |
| [LLM Startup Embraces AMD GPUs, Says ROCm Has â€˜Parityâ€™ With Nvidiaâ€™s CUDA Platform](https://www.crn.com/news/components-peripherals/llm-startup-embraces-amd-gpus-says-rocm-has-parity-with-nvidia-s-cuda-platform) ğŸŸ¢ | A startup called Lamini is using over 100 AMD Instinct MI200 GPUs and found that AMDâ€™s ROCm software platform rivals Nvidiaâ€™s CUDA platform. They claim that running a large language model on their platform is 10x cheaper than on Amazon Web Services. | [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [NVIDIA ğŸ®](Topic_NVIDIA.md) | 2023-10-02 |
| [Open ASR Leaderboard](https://huggingface.co/spaces/hf-audio/open_asr_leaderboard) ğŸŸ¢ | Hugging Face has released a speech-to-text leaderboard that ranks and assesses speech recognition models on their platform. The current top performers are NVIDIA FastConformer and OpenAI Whisper, with a focus on English speech recognition. Multilingual evaluation will be added in future updates. | [Hugging Face ğŸ¤—](Topic_Hugging_Face.md), [Speech-to-text ğŸ¤](Topic_Speech-to-text.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2023-09-11 |
| [NVIDIA and Hugging Face to Connect Millions of Developers to Generative AI Supercomputing](https://nvidianews.nvidia.com/news/nvidia-and-hugging-face-to-connect-millions-of-developers-to-generative-ai-supercomputing) ğŸŸ¢ | NVIDIA and Hugging Face have partnered to offer AI developers access to high-performance GPUs for deep learning through DGX Cloud integration. | [Hugging Face ğŸ¤—](Topic_Hugging_Face.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-08-14 |
| [Cerebras Systems signs $100 million AI supercomputer deal with UAEâ€™s G42](https://www.reuters.com/technology/cerebras-systems-signs-100-mln-ai-supercomputer-deal-with-uaes-g42-2023-07-20/) ğŸŸ¢ | Cerebras Systems has struck a $100 million deal with G42, marking the debut of AI supercomputers that could potentially challenge Nvidiaâ€™s market position. In response to chip shortages, cloud computing providers are seeking alternative solutions. To accelerate the rollout, Cerebras will construct three Condor Galaxy systems in the United States, with the first supercomputer set to go online this year, followed by two others in early 2024. | [Funding ğŸ’°](Topic_Funding.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-07-24 |
| [Nvidia deepens bets on AI in drug discovery with Recursion investment](https://www.reuters.com/technology/nvidia-invests-50-mln-recursion-train-ai-models-drug-discovery-2023-07-12/) ğŸŸ¢ | Nvidia invests $50M in Recursion, a biotech company using AI to revolutionize drug discovery. This partnership allows Recursion to utilize Nvidiaâ€™s platform and access their advanced AI technology. Recursionâ€™s share price surged by 83% post-announcement, highlighting the marketâ€™s recognition of AIâ€™s significance in drug discovery. | [AI in healthcare ğŸ¥](Topic_AI_in_healthcare.md), [Funding ğŸ’°](Topic_Funding.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-07-17 |
| [Inside Chinaâ€™s underground market for high-end Nvidia AI chips](https://www.reuters.com/technology/inside-chinas-underground-market-high-end-nvidia-ai-chips-2023-06-19/) ğŸ”´ | Despite U.S. export restrictions, Chinese demand for high-end Nvidia AI chips remains strong and vendors in Shenzhen and Hong Kong have emerged to offer them at steep prices in a de facto underground market. The exact volume of chip flow is unknown, but local authorities are also reported to be buyers. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [AI regulation ğŸ“œ](Topic_AI_regulation.md) | 2023-06-26 |
| [Chinaâ€™s ByteDance Has Gobbled Up $1 Billion of Nvidia GPUs for AI This Year](https://www.tomshardware.com/news/chinas-bytedance-has-gobbled-up-dollar1-billion-of-nvidia-gpus-for-ai-this-year) ğŸŸ¢ | Chinese tech giant ByteDance has reportedly invested $1 billion in Nvidiaâ€™s HPC products, including the A100 and H800 cards, totaling about 100,000 units, to fulfill the high demand for AI technology. China recognizes the impact of AI on the global market and has embraced it, investing heavily in HPC hardware. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-06-26 |
| [Nvidia demo about speaking to AI game characters](https://www.theverge.com/2023/5/28/23740908/nvidia-ace-demo-voice-ai-npc-game-characters) ğŸŸ¢ | Nvidia showcases a powerful AI-powered demo of conversational AI for game characters that enhances realism and engages players, providing game developers a tool to improve their gamesâ€™ storytelling and overall engagement. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Text-to-speech ğŸ“¢](Topic_Text-to-speech.md), [Speech-to-text ğŸ¤](Topic_Speech-to-text.md) | 2023-06-06 |
| [Why Nvidia is suddenly one of the most valuable companies in the world](https://www.washingtonpost.com/technology/2023/05/25/nvidia-ai-stock-gpu-chatbots/) ğŸŸ¢ | NVIDIAâ€™s GPUs have become a crucial component in developing AI, leading its worth to $939.3 billion; with AI applications requiring huge amounts of data, companies are buying thousands of NVIDIAâ€™s expensive chips. NVIDIAâ€™s dominance in the industry is predicted to persist as startups compete with big tech for access to its costly GPUs. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-06-06 |
| [Microsoft spent hundreds of millions of dollars on a ChatGPT supercomputer](https://www.theverge.com/2023/3/13/23637675/microsoft-chatgpt-bing-millions-dollars-supercomputer-openai) ğŸŸ¢ | Microsoft says it connected tens of thousands of Nvidia A100 chips and reworked server racks to build the hardware behind ChatGPT and its own Bing AI bot. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Microsoft ğŸªŸ](Topic_Microsoft.md), [ChatGPT ğŸ’¬](Topic_ChatGPT.md) | 2023-03-20 |
| [Nvidia Debuts Generative AI Model for Medical Research](https://voicebot.ai/2023/01/12/nvidia-debuts-generative-ai-model-for-medical-research/) ğŸŸ¢ | Nvidia and Evozyne have debuted ProT-VAE, a generative AI model capable of producing proteins to use in medicine and other industries. The model uses deep learning and generative AI to synthesize variants of proteins to create more effective enzymes. | [AI in healthcare ğŸ¥](Topic_AI_in_healthcare.md), [NVIDIA ğŸ®](Topic_NVIDIA.md) | 2023-01-23 |