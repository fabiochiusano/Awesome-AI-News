# Speech-to-text news

| Title | Summary | Topics | Week |
| --- | --- | --- | --- |
| [Announcements from OpenAI DevDay](https://openai.com/blog/new-models-and-developer-products-announced-at-devday) ğŸŸ¢ | OpenAI has introduced several new and improved models and APIs, including GPT-4 Turbo with a larger context window and lower prices, the ability to process images in the Chat Completions API, fine- tuning options for GPT-4 and GPT-3.5 Turbo, and the availability of DALLÂ·E 3 via API. They have also introduced features like JSON mode, improved instruction following, and parallel function calling. Additionally, there are new options for text-to-speech and the creation of â€œGPT assistants.â€ OpenAI has also released the Whisper large-v3 model for automatic speech recognition. | [Whisper ğŸ¤«](topics/Topic_Whisper_ğŸ¤«.md), [Text-to-speech ğŸ“¢](topics/Topic_Text-to-speech_ğŸ“¢.md), [Speech-to-text ğŸ¤](topics/Topic_Speech-to-text_ğŸ¤.md), [AI for images ğŸ–¼ï¸](topics/Topic_AI_for_images_ğŸ–¼ï¸.md), [Multimodal AI (image, video, audio) ğŸ“¸](topics/Topic_Multimodal_AI_(image_video_audio)_ğŸ“¸.md), [GPT-3, GPT-3.5, and GPT-3.5 turbo ğŸ’¡](topics/Topic_GPT-3_GPT-3.5_and_GPT-3.5_turbo_ğŸ’¡.md), [GPT-4 and GPT-4 turbo ğŸš€](topics/Topic_GPT-4_and_GPT-4_turbo_ğŸš€.md), [OpenAI ğŸŒŸ](topics/Topic_OpenAI_ğŸŒŸ.md) | 2023-11-13 |
| [ChatGPT can now see, hear, and speak](https://openai.com/blog/chatgpt-can-now-see-hear-and-speak) ğŸŸ¢ | OpenAI has introduced new voice and image capabilities to their AI assistant, ChatGPT. Users can now engage in natural voice conversations and receive relevant responses. The image feature enables users to show ChatGPT images for assistance in interpretation. | [Text-to-speech ğŸ“¢](topics/Topic_Text-to-speech_ğŸ“¢.md), [Speech-to-text ğŸ¤](topics/Topic_Speech-to-text_ğŸ¤.md), [AI for images ğŸ–¼ï¸](topics/Topic_AI_for_images_ğŸ–¼ï¸.md), [Multimodal AI (image, video, audio) ğŸ“¸](topics/Topic_Multimodal_AI_(image_video_audio)_ğŸ“¸.md), [OpenAI ğŸŒŸ](topics/Topic_OpenAI_ğŸŒŸ.md) | 2023-10-02 |
| [Open ASR Leaderboard](https://huggingface.co/spaces/hf-audio/open_asr_leaderboard) ğŸŸ¢ | Hugging Face has released a speech-to-text leaderboard that ranks and assesses speech recognition models on their platform. The current top performers are NVIDIA FastConformer and OpenAI Whisper, with a focus on English speech recognition. Multilingual evaluation will be added in future updates. | [Hugging Face ğŸ¤—](topics/Topic_Hugging_Face_ğŸ¤—.md), [Speech-to-text ğŸ¤](topics/Topic_Speech-to-text_ğŸ¤.md), [NVIDIA ğŸ®](topics/Topic_NVIDIA_ğŸ®.md), [OpenAI ğŸŒŸ](topics/Topic_OpenAI_ğŸŒŸ.md) | 2023-09-11 |
| [Introducing a foundational multimodal model for speech translation](https://ai.meta.com/blog/seamless-m4t/) ğŸŸ¢ | Meta has developed a powerful foundational model called SeamlessM4T that is capable of handling various text and speech tasks across 100 languages. It includes automatic speech recognition, speech-to-text translation, speech-to-speech translation, text-to-text translation, and text-to- speech translation, supporting a wide range of input and output languages. | [Text-to-speech ğŸ“¢](topics/Topic_Text-to-speech_ğŸ“¢.md), [Speech-to-text ğŸ¤](topics/Topic_Speech-to-text_ğŸ¤.md), [Multimodal AI (image, video, audio) ğŸ“¸](topics/Topic_Multimodal_AI_(image_video_audio)_ğŸ“¸.md), [Meta â™¾](topics/Topic_Meta_â™¾.md) | 2023-08-28 |
| [Nvidia demo about speaking to AI game characters](https://www.theverge.com/2023/5/28/23740908/nvidia-ace-demo-voice-ai-npc-game-characters) ğŸŸ¢ | Nvidia showcases a powerful AI-powered demo of conversational AI for game characters that enhances realism and engages players, providing game developers a tool to improve their gamesâ€™ storytelling and overall engagement. | [NVIDIA ğŸ®](topics/Topic_NVIDIA_ğŸ®.md), [Multimodal AI (image, video, audio) ğŸ“¸](topics/Topic_Multimodal_AI_(image_video_audio)_ğŸ“¸.md), [Text-to-speech ğŸ“¢](topics/Topic_Text-to-speech_ğŸ“¢.md), [Speech-to-text ğŸ¤](topics/Topic_Speech-to-text_ğŸ¤.md) | 2023-06-06 |
| [Introducing speech-to-text, text-to-speech, and more for 1,100+ languages](https://ai.facebook.com/blog/multilingual-model-speech-recognition/) ğŸŸ¢ | Metaâ€™s Massively Multilingual Speech project uses self-supervised learning with wav2vec 2.0 and a unique dataset to enable AI to understand and generate speech in over 1,100 languages, outperforming existing models with reduced character error rates and increased language coverage. | [AI datasets ğŸ“Š](topics/Topic_AI_datasets_ğŸ“Š.md), [Text-to-speech ğŸ“¢](topics/Topic_Text-to-speech_ğŸ“¢.md), [Speech-to-text ğŸ¤](topics/Topic_Speech-to-text_ğŸ¤.md), [Meta â™¾](topics/Topic_Meta_â™¾.md) | 2023-05-29 |
| [Googleâ€™s Universal Speech Model (USM): State-of-the-art speech AI for 100+ languages](https://ai.googleblog.com/2023/03/universal-speech-model-usm-state-of-art.html)  | USM is a family of state-of-the-art speech models with 2B parameters, trained on 12 million hours of speech and 28 billion sentences of text, spanning 300+ languages. | [Speech-to-text ğŸ¤](topics/Topic_Speech-to-text_ğŸ¤.md), [Google ğŸ”](topics/Topic_Google_ğŸ”.md) | 2023-03-13 |
| [MuAViC: The first audio-video speech translation benchmark](https://ai.facebook.com/blog/muavic-audio-visual-speech-translation-benchmark/) ğŸŸ¢ | Using visual information to improve performance for English speech recognition tasks. | [Speech-to-text ğŸ¤](topics/Topic_Speech-to-text_ğŸ¤.md), [Multimodal AI (image, video, audio) ğŸ“¸](topics/Topic_Multimodal_AI_(image_video_audio)_ğŸ“¸.md) | 2023-03-13 |
| [Hugging Face releases SpeechT5](https://huggingface.co/blog/speecht5) ğŸŸ¢ | a model able to do speech-to-text, text-to-speech, and speech-to-speech. | [Hugging Face ğŸ¤—](topics/Topic_Hugging_Face_ğŸ¤—.md), [Text-to-speech ğŸ“¢](topics/Topic_Text-to-speech_ğŸ“¢.md), [Speech-to-text ğŸ¤](topics/Topic_Speech-to-text_ğŸ¤.md), [Multimodal AI (image, video, audio) ğŸ“¸](topics/Topic_Multimodal_AI_(image_video_audio)_ğŸ“¸.md), [Model release ğŸ‰](topics/Topic_Model_release_ğŸ‰.md) | 2023-02-13 |