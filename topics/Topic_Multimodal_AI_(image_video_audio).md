# Multimodal AI (image, video, audio) news

| Title | Summary | Topics | Week |
| --- | --- | --- | --- |
| [Meta releases Llama 3.2](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/) ğŸŸ¢ | Llama 3.2 features advanced AI models, including vision LLMs (11B and 90B) and lightweight text-only models (1B and 3B), optimized for edge and mobile devices. These models excel in tasks such as summarization and image understanding, supporting extensive token lengths. | [Model release ğŸ‰](Topic_Model_release.md), [LLaMA ğŸ¦™](Topic_LLaMA.md), [Meta â™¾](Topic_Meta.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-09-30 |
| [Mistral releases Pixtral 12B, its first multimodal model](https://techcrunch.com/2024/09/11/mistral-releases-pixtral-its-first-multimodal-model/) ğŸŸ¢ | Mistral has introduced Pixtral 12B, a 12-billion-parameter multimodal AI model that processes both text and images. Building on features from their previous text model, Nemo 12B, Pixtral 12B is available for free download on GitHub and Hugging Face under an Apache 2.0 license. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Model release ğŸ‰](Topic_Model_release.md), [Mistral ğŸŒ¬ï¸](Topic_Mistral.md) | 2024-09-16 |
| [Alibaba releases new AI model Qwen2-VL that can analyze videos more than 20 minutes long](https://venturebeat.com/ai/alibaba-releases-new-ai-model-qwen2-vl-that-can-analyze-videos-more-than-20-minutes-long/) ğŸŸ¢ | Alibaba Cloudâ€™s new AI model, Qwen2-VL, excels in video analysis and multilingual comprehension, outperforming Metaâ€™s Llama 3.1 and Googleâ€™s Gemini-1.5 in benchmarks. It supports multiple languages and extended video content analysis, and is available in three sizes, with two being open-sourced. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Model release ğŸ‰](Topic_Model_release.md), [Google Gemini ğŸŒŒ](Topic_Google_Gemini.md) | 2024-09-09 |
| [Google rolling out Gems and Imagen 3 to Gemini Advanced](https://9to5google.com/2024/08/28/gemini-advanced-gems-imagen-3/) ğŸŸ¢ | Googleâ€™s Gemini has launched Gems, a feature for custom task-oriented version creation, and Imagen 3, an advanced image generation tool that includes ethically-guided people generation, for Advanced subscribers to boost productivity and creativity. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Google Gemini ğŸŒŒ](Topic_Google_Gemini.md), [Google ğŸ”](Topic_Google.md) | 2024-09-02 |
| [Runwayâ€™s Gen-3 Alpha Turbo is here and can make AI videos faster than you can type](https://venturebeat.com/ai/runways-gen-3-alpha-turbo-is-here-and-can-make-ai-videos-faster-than-you-can-type/) ğŸŸ¢ | Runway ML introduces Gen-3 Alpha Turbo, an AI video generation model delivering 7x speed improvements and 50% cost reduction. Widely available across subscription plans, the model addresses diverse needs while promising advancements amidst ethical scrutiny, signaling Runwayâ€™s ambition for market leadership. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Model release ğŸ‰](Topic_Model_release.md) | 2024-08-26 |
| [Xâ€™s new AI image generator will make anything from Taylor Swift in lingerie to Kamala Harris with a gun](https://www.theverge.com/2024/8/14/24220173/xai-grok-image-generator-misinformation-offensive-imges) ğŸ”´ | Grok, xAIâ€™s new chatbot released on Elon Muskâ€™s platform X, enables generation of images from text prompts with minimal content restrictions. However, its production of controversial content has highlighted a stark difference in policy enforcement compared to other AI services, raising concerns about regulation and digital safety, which could impact the platformâ€™s relationship with advertisers and attract attention from European regulators. | [AI safety ğŸ”](Topic_AI_safety.md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [AI regulation ğŸ“œ](Topic_AI_regulation.md), [Grok ğŸ¦](Topic_Grok.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-08-19 |
| [The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery](https://sakana.ai/ai-scientist/) ğŸŸ¢ | Sakana AI has launched The AI Scientist, an automated system designed to advance scientific discovery in areas such as diffusion models and transformers. Working with leading academic partners, it can produce and assess scientific papers, offering cost savings but with current limitations including no visual capabilities and potential inaccuracies. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-08-19 |
| [Introducing SAM 2: The next generation of Meta Segment Anything Model for videos and images](https://ai.meta.com/blog/segment-anything-2/) ğŸŸ¢ | Meta has launched SAM 2, an improved AI model for prompt-based real-time video and image segmentation, featuring zero-shot learning and requiring three times fewer interactions. SAM 2 is now available as open-source under the Apache 2.0 license. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Model release ğŸ‰](Topic_Model_release.md), [Meta â™¾](Topic_Meta.md) | 2024-08-06 |
| [Instagram starts letting people create AI versions of themselves](https://www.theverge.com/24209196/instagram-ai-characters-meta-ai-studio-release) ğŸŸ¢ | Metaâ€™s AI Studio has launched a new feature for Instagram and other Meta platforms, enabling users to generate AI-crafted avatars of themselves for use across social media and the web. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Meta â™¾](Topic_Meta.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-08-06 |
| [Stability AI Releases Stable Assistant Features](https://stability.ai/news/stability-ai-releases-stable-assistant-features) ğŸŸ¢ | Stability AI has enhanced its Stable Assistant with new capabilities from Stable Diffusion 3, featuring â€œSearch & Replaceâ€ for object swapping in images, alongside existing functions for image editing, upscaling, and video generation. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Stable Diffusion ğŸ¨](Topic_Stable_Diffusion.md), [Stability AI âš–ï¸](Topic_Stability_AI.md) | 2024-07-15 |
| [Adept joins Amazon](https://www.adept.ai/blog/adept-update) ğŸŸ¢ | The team from Adept, including its co-founders, is integrating into Amazonâ€™s AGI division, aiming to advance general intelligence efforts. Amazon has licensed Adeptâ€™s advanced multimodal agent technology and acquired select datasets. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Amazon ğŸŒ³](Topic_Amazon.md) | 2024-07-08 |
| [YouTube now lets you request removal of AI-generated content that simulates your face or voice](https://techcrunch.com/2024/07/01/youtube-now-lets-you-request-removal-of-ai-generated-content-that-simulates-your-face-or-voice/) ğŸŸ¢ | YouTubeâ€™s revised privacy policy now enables users to request the removal of deepfake content replicating their likeness if it raises privacy issues, with certain considerations for content context and public interest. | [AI safety ğŸ”](Topic_AI_safety.md), [AI and copyright Â©ï¸](Topic_AI_and_copyright.md), [AI regulation ğŸ“œ](Topic_AI_regulation.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Google ğŸ”](Topic_Google.md) | 2024-07-08 |
| [Meet Figma AI: Empowering designers with intelligent tools](https://www.figma.com/blog/introducing-figma-ai/) ğŸŸ¢ | Figma has launched Figma AI, a new AI-enhanced design platform featuring AI-driven search capabilities, generative text and image tools, and advanced prototyping functionalities. Itâ€™s currently in beta and free until 2024, though usage may be capped depending on the cost of tools. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-07-01 |
| [Snapchat AI turns prompts into new lens](https://www.theverge.com/2024/6/19/24181965/snapchat-ai-prompt-custom-lens) ğŸŸ¢ | Snapchat has launched a feature enabling users to create custom AI-driven lenses using textual prompts, leveraging user interaction data and online activity to tailor experiences. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-07-01 |
| [Introducing Claude 3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet) ğŸŸ¢ | The latest Claude 3.5 Sonnet upgrade offers enhanced intelligence, increased processing speed, and improved efficiency at a competitive price, with notable advancements in reasoning, coding, and vision processing. Additionally, the newly introduced â€˜Artifactsâ€™ feature enables real-time collaboration. | [AI for coding ğŸ‘¨â€ğŸ’»](Topic_AI_for_coding.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Claude ğŸ–‹ï¸](Topic_Claude.md) | 2024-06-24 |
| [Introducing Gen-3 Alpha: A New Frontier for Video Generation](https://runwayml.com/blog/introducing-gen-3-alpha/) ğŸŸ¢ | Runway has launched Gen-3 Alpha, an advanced AI capable of generating videos and images from text and images. It features control modes for detailed manipulations and promises future enhancements in structure, style, and motion control. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-06-24 |
| [Indian election was awash in deepfakes â€” but AI was a net positive for democracy](https://theconversation.com/indian-election-was-awash-in-deepfakes-but-ai-was-a-net-positive-for-democracy-231795) ğŸŸ¢ | Indiaâ€™s 2024 elections saw AI advancements in voter engagement through deepfake communication and real-time multi-language translation. Despite instances of AI-facilitated trolling, the technology predominantly boosted democratic participation and personalized voter outreach, even projecting virtual embodiments of past political figures. | [AI safety ğŸ”](Topic_AI_safety.md), [AI regulation ğŸ“œ](Topic_AI_regulation.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-06-24 |
| [Generating audio for video](https://deepmind.google/discover/blog/generating-audio-for-video/) ğŸŸ¢ | DeepMind has created a V2A (Video-to-Audio) system using a diffusion-based AI model for generating synchronized audio for silent videos, guided by visual and textual cues to produce lifelike sound environments. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [DeepMind ğŸ§©](Topic_DeepMind.md) | 2024-06-24 |
| [Luma Dream Machine](https://lumalabs.ai/dream-machine) ğŸŸ¢ | The Luma Dream Machine by Lumalabs is an AI model designed for synthesizing high-quality, realistic videos from text and images, leveraging a transformer-based method optimized for video content. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md) | 2024-06-17 |
| [Stability AI releases a sound generator](https://techcrunch.com/2024/06/05/stability-ai-releases-a-sound-generator/) ğŸŸ¢ | Stability AI has launched â€œStable Audio Open,â€ an AI model that generates sound from text descriptions using royalty-free samples, geared towards non-commercial use. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Model release ğŸ‰](Topic_Model_release.md), [Stability AI âš–ï¸](Topic_Stability_AI.md) | 2024-06-10 |
| [OpenAI releases GPT-4o](https://openai.com/index/spring-update/) ğŸŸ¢ | OpenAI released the new model GPT-4o, capable of processing and generating text, audio, and image inputs and outputs. It boasts quick audio response times on par with humans, enhanced non-English language processing, and cost-efficient API usage, while maintaining GPT-4 Turboâ€™s performance levels. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Model release ğŸ‰](Topic_Model_release.md), [GPT-4 and GPT-4 turbo ğŸš€](Topic_GPT-4_and_GPT-4_turbo.md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2024-05-21 |
| [100 things Google announced at I/O 2024](https://blog.google/technology/ai/google-io-2024-100-announcements/) ğŸŸ¢ | At Google I/O 2024, notable AI developments were announced such as Gemini 1.5 models, Trillium TPU, and enhanced AI in Google Search. Key introductions include Imagen 3 for image creation, Veo for video generation, and upgraded features in the Gemini app for premium users, alongside new generative media tools. | [Google Gemini ğŸŒŒ](Topic_Google_Gemini.md), [Google ğŸ”](Topic_Google.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-05-21 |
| [OpenAI CEO Sam Altman says GPT-4 is the dumbest AI model youâ€™ll ever have to use again](https://the-decoder.com/openai-ceo-sam-altman-promises-ai-models-that-far-surpass-gpt-4/) ğŸŸ¢ | OpenAIâ€™s Sam Altman considers GPT-4 the most rudimentary AI that users will encounter as the company progresses towards more sophisticated models like GPT-5, which is expected to feature enhanced abilities such as video generation. He foresees AI developing into highly efficient assistants, performing tasks and providing solutions effortlessly. | [GPT-4 and GPT-4 turbo ğŸš€](Topic_GPT-4_and_GPT-4_turbo.md), [GPT-5 ğŸ”®](Topic_GPT-5.md), [OpenAI ğŸŒŸ](Topic_OpenAI.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-05-06 |
| [Pro music video powered by OpenAIâ€™s Sora released in a world-first](https://interestingengineering.com/culture/sora-powered-music-video) ğŸŸ¢ | Paul Trillo directed the official music video for Washed Outâ€™s â€œThe Hardest Partâ€ using OpenAIâ€™s Sora, a text-to-video AI, producing 700 clips of which 55 were used. The project has stirred ethical discussions within the AI industry. | [AI and copyright Â©ï¸](Topic_AI_and_copyright.md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2024-05-06 |
| [Metaâ€™s open source GPT-4 competitor Llama 3 is coming soon](https://the-decoder.com/metas-open-source-gpt-4-competitor-llama-3-is-coming-soon/) ğŸŸ¢ | Meta is set to release Llama 3, an AI assistant intended to outperform its predecessors and compete with OpenAIâ€™s GPT-4. It will debut with two preliminary versions before launching a comprehensive multimodal iteration in the summer. | [LLaMA ğŸ¦™](Topic_LLaMA.md), [Meta â™¾](Topic_Meta.md), [GPT-4 and GPT-4 turbo ğŸš€](Topic_GPT-4_and_GPT-4_turbo.md), [OpenAI ğŸŒŸ](Topic_OpenAI.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-04-15 |
| [Gemini 1.5 Pro Now Available in 180+ Countries; With Native Audio Understanding, System Instructions, JSON Mode and More](https://developers.googleblog.com/2024/04/gemini-15-pro-in-public-preview-with-new-features.html) ğŸŸ¢ | Gemini 1.5 Pro has launched globally, offering cutting-edge native audio understanding and upgraded features such as a File API, system instructions, JSON mode for developers, along with advanced audio/video modalities, including video quiz capabilities. The update also introduces a highly performant text embedding model. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-04-15 |
| [GPT4 Turbo has been upgraded and is out of preview](https://platform.openai.com/docs/models/continuous-model-upgrades) ğŸŸ¢ | The new GPT-4 Turbo, now with vision capabilities, supports vision requests via JSON mode and function calls, with knowledge updated until December 2023. | [GPT-4 and GPT-4 turbo ğŸš€](Topic_GPT-4_and_GPT-4_turbo.md), [OpenAI ğŸŒŸ](Topic_OpenAI.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-04-15 |
| [x.AI Unveils itâ€™s First Multimodal model, Grok-1.5 Vision](https://www.maginative.com/article/x-ai-unveils-its-first-multimodal-model-grok-1-5-vision/) ğŸŸ¢ | x.AI, launched by Elon Musk, introduces Grok-1.5V, an advanced multimodal AI model with enhanced capabilities for analyzing visual data, including text, charts, and images. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Grok ğŸ¦](Topic_Grok.md) | 2024-04-15 |
| [TikTok may add AI avatars that can make ads](https://www.theverge.com/2024/4/11/24127579/tiktok-ai-virtual-influencers-advertising) ğŸŸ¢ | TikTok is investigating the integration of AI-powered avatars to deliver more personalized and engaging advertising experiences by aligning ad content with user interests. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-04-15 |
| [Introducing Stable Audio 2.0 from Stability AI](https://stability.ai/news/stable-audio-2-0) ğŸŸ¢ | Stable Audio 2.0 introduces significant advancements in music generation AI, offering audio-to-audio conversion through natural language prompts and expanding creative possibilities with sound effects and improved style transfer. The latest version now supports the generation of high-quality (44.1 kHz) structured songs up to three minutes in length from concise prompts. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Stability AI âš–ï¸](Topic_Stability_AI.md) | 2024-04-08 |
| [OpenAIâ€™s Sora just made its first music video and itâ€™s like a psychedelic trip](https://www.techradar.com/computing/artificial-intelligence/openais-sora-just-made-its-first-music-video-and-its-like-a-psychedelic-trip) ğŸŸ¢ | OpenAI has showcased the capabilities of its text-to-video engine, Sora, by creating a music video for August Kampâ€™s song â€œWorldweightâ€ entirely through the engineâ€™s capabilities. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2024-04-08 |
| [Introducing Stable Video 3D: Quality Novel View Synthesis and 3D Generation from Single Images](https://stability.ai/news/introducing-stable-video-3d) ğŸŸ¢ | Stability AI has introduced Stable Video 3D (SV3D), a new generative model enhancing 3D tech with better quality and consistency. SV3D offers two versions: SV3D_u for single-image-based orbital videos without camera paths, and SV3D_p for more advanced 3D video creation using specified camera trajectories. For commercial use, it requires a Stability AI Membership, while non-commercial users can access the model weights through Hugging Face and consult the accompanying research paper. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Stability AI âš–ï¸](Topic_Stability_AI.md) | 2024-03-25 |
| [SIMA generalist AI agent for 3D virtual environments](https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/) ğŸŸ¢ | DeepMind has developed SIMA, a generalist AI agent designed to operate within 3D virtual environments, focusing on interpreting natural language and navigating complex problems rather than traditional game score maximization. SIMA has been trained across nine games from various genres and features a combination of pre-trained image recognition and memory-based models to process and act on both visual cues and linguistic instructions. | [Reinforcement learning ğŸ®](Topic_Reinforcement_learning.md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [DeepMind ğŸ§©](Topic_DeepMind.md) | 2024-03-18 |
| [Midjourney debuts feature for generating consistent characters across multiple gen AI images](https://venturebeat.com/ai/midjourney-debuts-feature-for-generating-consistent-characters-across-multiple-gen-ai-images/) ğŸŸ¢ | Midjourney has introduced an update enabling AI-generated character consistency in artwork through new tagging features. The â€œ â€” crefâ€ tag allows users to reference a character image URL to maintain the characterâ€™s appearance across different scenes, while the â€œ â€” cwâ€ tag adjusts the level of character consistency. This facilitates continuity in visual storytelling within the AI art community, although the precision of replication can vary. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Midjourney ğŸ›¤ï¸](Topic_Midjourney.md) | 2024-03-18 |
| [Introducing the next generation of Claude](https://www.anthropic.com/news/claude-3-family) ğŸŸ¢ | Anthropic has launched Claude 3, a new AI that surpasses GPT-4, with three models: Opus, Sonnet, and Haiku. Each supports a 200k context window, vision abilities, and multiple languages. Opus is touted as the top performer. Sonnet is integrated with Amazon Bedrock and Google Cloudâ€™s Vertex AI, while Opus and Haiku are slated for future release along with new features like function calling and REPL. | [Claude ğŸ–‹ï¸](Topic_Claude.md), [Anthropic ğŸŒ](Topic_Anthropic.md), [Model release ğŸ‰](Topic_Model_release.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Google ğŸ”](Topic_Google.md), [Amazon ğŸŒ³](Topic_Amazon.md), [GPT-4 and GPT-4 turbo ğŸš€](Topic_GPT-4_and_GPT-4_turbo.md) | 2024-03-11 |
| [OpenAI announces Sora](https://openai.com/sora) ğŸŸ¢ | OpenAI has unveiled Sora, a novel AI video generator capable of crafting up to minute-long videos from textual prompts. Demonstrations showcase its ability to transform creative prompts into video content, emphasizing the synergy between AI and human creativity. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2024-02-19 |
| [V-JEPA: The next step toward advanced machine intelligence](https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/) ğŸŸ¢ | Yann LeCun proposes a machine learning paradigm, V-JEPA, to enable systems to build internal world models and learn intuitively like a human. Unlike conventional methods, V-JEPA employs a non-generative technique for video understanding, prioritizing abstract interpretation over detailed reproduction. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-02-19 |
| [Deepfake â€˜face swapâ€™ attacks surged 704% last year, study finds](https://thenextweb.com/news/deepfake-face-swap-attacks-increase) ğŸ”´ | Deepfake technology advancements have resulted in a significant rise in â€˜face swapâ€™ attacks, with a 704% increase in the second half of the year, driven by accessible GenAI tools such as SwapFace and DeepFaceLive. These tools enhance the ability to produce undetectable deepfakes, facilitating anonymity and contributing to a spike in deepfake-enabled crimes, including a notable financial scam in Hong Kong. | [AI safety ğŸ”](Topic_AI_safety.md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [AI regulation ğŸ“œ](Topic_AI_regulation.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-02-12 |
| [Labeling AI-Generated Images on Facebook, Instagram and Threads](https://about.fb.com/news/2024/02/labeling-ai-generated-images-on-facebook-instagram-and-threads/) ğŸŸ¢ | Meta is implementing â€œImagined with AIâ€ labels for AI-generated content on Facebook and Instagram for greater transparency. While AI image labeling is available, Meta is developing detection for audio/video content and requires user disclosure until standards are established. Additionally, measures are being taken to ensure these transparency labels cannot be removed. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Meta â™¾](Topic_Meta.md) | 2024-02-12 |
| [Voice cloning startup ElevenLabs lands $80M, achieves unicorn status](https://techcrunch.com/2024/01/22/voice-cloning-startup-elevenlabs-lands-80m-achieves-unicorn-status/) ğŸŸ¢ | ElevenLabs has achieved unicorn status after securing an $80 million Series B round led by Andreessen Horowitz, raising their total funds to $101 million. Founded by Piotr Dabkowski and CEO Mati Staniszewski, the company specializes in realistic voice synthesis through a web app, targeting applications in audiobooks, gaming, and screen dubbing within the expanding audio media market. | [Text-to-speech ğŸ“¢](Topic_Text-to-speech.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Funding ğŸ’°](Topic_Funding.md) | 2024-01-29 |
| [Google introduces Gemini](https://blog.google/technology/ai/google-gemini-ai/#capabilities) ğŸŸ¢ | Google has introduced Gemini, a new model that comes in three sizes: Ultra, Pro, and Nano. Gemini is natively multimodal and outperforms other models in various academic benchmarks. Notably, Gemini Ultra achieves a groundbreaking score on a multitask language understanding test and excels in image benchmarks without relying on OCR systems. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Google Gemini ğŸŒŒ](Topic_Google_Gemini.md), [Google ğŸ”](Topic_Google.md) | 2023-12-11 |
| [Pika Wows in Debut as AI Video Generator Takes Aim at Tech Giants](https://decrypt.co/207799/pika-ai-video-tool-blasts-out-of-beta) ğŸŸ¢ | Pika Labs has released Pika 1.0, an impressive AI video generation tool. It has advanced features like Text-to-Video and Image-to-Video conversion. The company has also raised $55 million in funding. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Funding ğŸ’°](Topic_Funding.md) | 2023-12-04 |
| [Introducing SDXL Turbo: A Real-Time Text-to-Image Generation Model](https://stability.ai/news/stability-ai-sdxl-turbo) ğŸŸ¢ | Stability AI introduces SDXL Turbo, a new text-to-image model that uses Adversarial Diffusion Distillation (ADD) to generate high-quality images rapidly and in a single step. It enables the quick and precise creation of 512 x 512 images in just over 200 milliseconds. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Stable Diffusion ğŸ¨](Topic_Stable_Diffusion.md), [Stability AI âš–ï¸](Topic_Stability_AI.md) | 2023-12-04 |
| [Introducing Stable Video Diffusion â€” Stability AI](https://stability.ai/news/stable-video-diffusion-open-ai-video-model) ğŸŸ¢ | Stability AI has introduced Stable Video Diffusion, a powerful foundation model for generative video. This model has the potential to generate customizable frames at varying frame rates and is publicly accessible on GitHub and Hugging Face for research purposes. | [Hugging Face ğŸ¤—](Topic_Hugging_Face.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Stability AI âš–ï¸](Topic_Stability_AI.md) | 2023-11-27 |
| [Off/Script launches an app to create and buy AI-designed fashion](https://techcrunch.com/2023/11/21/off-script-launches-ai-app/) ğŸŸ¢ | Off/Script has launched a mobile app that allows users in the AI field to design, share, and potentially sell AI-generated fashion and product concepts. The platform uses voting to fund and produce the top-ranked ideas, working with a large network of manufacturers to bring these concepts to life. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Funding ğŸ’°](Topic_Funding.md) | 2023-11-27 |
| [DeepMind introduces Lyria, a model for music generation](https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/) ğŸŸ¢ | Google DeepMindâ€™s AI music model, Lyria, is transforming the music creation process by producing exceptional quality music with customizable vocals. The â€˜Dream Trackâ€™ experiment on YouTube enables artists to connect with fans through AI-generated voice and music, while AI tools enhance the creative journey for professionals in the music industry. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [DeepMind ğŸ§©](Topic_DeepMind.md), [Google ğŸ”](Topic_Google.md) | 2023-11-20 |
| [Announcements from OpenAI DevDay](https://openai.com/blog/new-models-and-developer-products-announced-at-devday) ğŸŸ¢ | OpenAI has introduced several new and improved models and APIs, including GPT-4 Turbo with a larger context window and lower prices, the ability to process images in the Chat Completions API, fine- tuning options for GPT-4 and GPT-3.5 Turbo, and the availability of DALLÂ·E 3 via API. They have also introduced features like JSON mode, improved instruction following, and parallel function calling. Additionally, there are new options for text-to-speech and the creation of â€œGPT assistants.â€ OpenAI has also released the Whisper large-v3 model for automatic speech recognition. | [Whisper ğŸ¤«](Topic_Whisper.md), [Text-to-speech ğŸ“¢](Topic_Text-to-speech.md), [Speech-to-text ğŸ¤](Topic_Speech-to-text.md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [GPT-3, GPT-3.5, and GPT-3.5 turbo ğŸ’¡](Topic_GPT-3_GPT-3.5_and_GPT-3.5_turbo.md), [GPT-4 and GPT-4 turbo ğŸš€](Topic_GPT-4_and_GPT-4_turbo.md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2023-11-13 |
| [Googleâ€™s new Image and Source checker](https://blog.google/products/search/google-search-new-fact-checking-features/) ğŸŸ¢ | Google has introduced new image and source verification tools that utilize AI to detect manipulated visuals and summarize credible sources. This aims to enhance transparency and provide faster access to background information, benefiting journalists investigating questionable images. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Google Gemini ğŸŒŒ](Topic_Google_Gemini.md), [Google ğŸ”](Topic_Google.md) | 2023-10-30 |
| [Fuyu-8B: A Multimodal Architecture for AI Agents](https://www.adept.ai/blog/fuyu-8b) ğŸŸ¢ | Adept has introduced Fuyu-8B, a powerful open-source vision-language model designed for comprehending and responding to questions regarding images, charts, diagrams, and documents. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md) | 2023-10-23 |
| [AI Just Deciphered an Ancient Herculaneum Scroll Without Unrolling It](https://decrypt.co/201411/ai-deciphered-herculaneum-scroll) ğŸŸ¢ | A 21-year-old student from the University of Nebraska-Lincoln used AI to decipher Greek letters from an unopened scroll discovered after the eruption of Mount Vesuvius in 79 AD. By utilizing a machine learning algorithm, the student successfully identified Greek characters like â€œporphyrasâ€ meaning purple and won the Vesuvius Challenge. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-10-16 |
| [Scaling GAIA-1: 9-billion parameter generative world model for autonomous driving](https://wayve.ai/thinking/scaling-gaia-1/) ğŸŸ¢ | GAIA-1 is a powerful 9B model designed for autonomous driving that generates synthetic data. It utilizes a video modeling approach, similar to LLMs, by predicting the next token. Trained on a substantial dataset, including 4,700 hours of London driving data, GAIA-1 is highly accurate in generating more data. | [AI datasets ğŸ“Š](Topic_AI_datasets.md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Robotics ğŸ¤–](Topic_Robotics.md) | 2023-10-10 |
| [ChatGPT can now see, hear, and speak](https://openai.com/blog/chatgpt-can-now-see-hear-and-speak) ğŸŸ¢ | OpenAI has introduced new voice and image capabilities to their AI assistant, ChatGPT. Users can now engage in natural voice conversations and receive relevant responses. The image feature enables users to show ChatGPT images for assistance in interpretation. | [Text-to-speech ğŸ“¢](Topic_Text-to-speech.md), [Speech-to-text ğŸ¤](Topic_Speech-to-text.md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2023-10-02 |
| [OpenAI announces DALLÂ·E 3](https://openai.com/dall-e-3) ğŸŸ¢ | OpenAI is launching DALLÂ·E 3, an improved version that excels in following instructions, requires less prompt engineering, and can communicate with ChatGPT. This integration enables users to refine prompts for DALLÂ·E 3 by describing their ideas to ChatGPT. Starting in October, DALLÂ·E 3 will be available to ChatGPT Plus and Enterprise customers. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [ChatGPT ğŸ’¬](Topic_ChatGPT.md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2023-09-25 |
| [Announcing Microsoft Copilot, your everyday AI companion](https://blogs.microsoft.com/blog/2023/09/21/announcing-microsoft-copilot-your-everyday-ai-companion/) ğŸŸ¢ | Microsoft Copilot will provide tailored assistance based on workplace data and web context. It enhances productivity and creativity in Windows 11, Microsoft 365, Edge, and Bing, while prioritizing privacy. Additionally, Bing and Edge users will enjoy a personalized experience with OpenAIâ€™s DALL.E 3 model, including AI shopping and image creation. | [Microsoft ğŸªŸ](Topic_Microsoft.md), [OpenAI ğŸŒŸ](Topic_OpenAI.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md) | 2023-09-25 |
| [How California is using AI to snuff out wildfires before they explode](https://edition.cnn.com/2023/09/23/us/fighting-wildfire-with-ai-california-climate/index.html) ğŸŸ¢ | The California Department of Forestry and Fire Protection is utilizing AI technology to improve wildfire detection and response. Through the Alert California program, AI scans the wilderness for anomalies like smoke, alerting officials when fires are detected. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-09-25 |
| [Stable Audio](https://www.stableaudio.com/) ğŸŸ¢ | London-based startup Stability AI, known for its AI model Stable Diffusion, has launched Stable Audio, an AI model that can generate high-quality commercial music with more control over synthesized audio. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Stable Diffusion ğŸ¨](Topic_Stable_Diffusion.md), [Stability AI âš–ï¸](Topic_Stability_AI.md) | 2023-09-18 |
| [Adobeâ€™s Firefly generative AI models are now generally available](https://techcrunch.com/2023/09/13/adobes-firefly-generative-ai-models-are-now-generally-available-get-pricing-plans/) ğŸŸ¢ | Adobe has released commercially available generative AI models in their Creative Cloud, including a standalone web app called Firefly. The new â€œgenerative creditsâ€ system controls user interactions with Fireflyâ€™s AI models, with each click on â€˜generateâ€™ using one credit. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Model release ğŸ‰](Topic_Model_release.md) | 2023-09-18 |
| [Ideogram launches AI image generator with impressive typography](https://venturebeat.com/ai/watch-out-midjourney-ideogram-launches-ai-image-generator-with-impressive-typography/) ğŸŸ¢ | Ideogram is an alternative AI tool that excels in generating images with strong typography capabilities. It offers a unique feature of generating text within images, effectively addressing the common challenge faced by popular AI image generators. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-09-05 |
| [Identifying AI-generated images with SynthID](https://www.deepmind.com/blog/identifying-ai-generated-images-with-synthid) ğŸŸ¢ | SynthID is a technology that uses imperceptible digital watermarks to identify AI- generated images, even after modifications like filters, color changes, and compression. | [AI safety ğŸ”](Topic_AI_safety.md), [AI and copyright Â©ï¸](Topic_AI_and_copyright.md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-09-05 |
| [Introducing a foundational multimodal model for speech translation](https://ai.meta.com/blog/seamless-m4t/) ğŸŸ¢ | Meta has developed a powerful foundational model called SeamlessM4T that is capable of handling various text and speech tasks across 100 languages. It includes automatic speech recognition, speech-to-text translation, speech-to-speech translation, text-to-text translation, and text-to- speech translation, supporting a wide range of input and output languages. | [Text-to-speech ğŸ“¢](Topic_Text-to-speech.md), [Speech-to-text ğŸ¤](Topic_Speech-to-text.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Meta â™¾](Topic_Meta.md) | 2023-08-28 |
| [Introducing IDEFICS: An Open Reproduction of State-of-the-art Visual Langage Model](https://huggingface.co/blog/idefics) ğŸŸ¢ | IDEFICS is an impressive open-source visual language model with 9 billion and 80 billion parameters, based on DeepMindâ€™s Flamingo. It offers the ability to describe images, generate stories, and answer image-related questions. Itâ€™s trained on diverse open datasets such as Wikipedia, Public Multimodal Dataset, LAION, and OBELICS. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [DeepMind ğŸ§©](Topic_DeepMind.md) | 2023-08-28 |
| [AudioCraft: A simple one-stop shop for audio modeling](https://ai.meta.com/blog/audiocraft-musicgen-audiogen-encodec-generative-ai-audio/) ğŸŸ¢ | Meta has released the code and weights for their AudioCraft models, including MusicGen and AudioGen. These models generate music and audio respectively, based on text-based user inputs. The release also includes the EnCodec decoder, which improves music quality. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Model release ğŸ‰](Topic_Model_release.md), [Meta â™¾](Topic_Meta.md) | 2023-08-07 |
| [NASA and IBM Openly Release Geospatial AI Foundation Model for NASA Earth Observation Data](https://www.earthdata.nasa.gov/news/impact-ibm-hls-foundation-model) ğŸŸ¢ | NASA and IBM Research have collaborated to release the HLS Geospatial FM, an open-source geospatial AI model for Earth observation data. This model has shown success in various applications such as flood mapping, burn scar identification, and predicting crop yields. | [AI datasets ğŸ“Š](Topic_AI_datasets.md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Model release ğŸ‰](Topic_Model_release.md) | 2023-08-07 |
| [YouTube uses AI to summarize videos in latest test](https://www.theverge.com/2023/8/1/23815321/youtube-ai-video-summaries) ğŸŸ¢ | YouTube is currently testing AI-generated video summaries to help viewers quickly determine the relevance of a video. The feature uses generative AI and will initially be available for English- language vlogs, shopping, and how-to videos on mobile devices. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Google Gemini ğŸŒŒ](Topic_Google_Gemini.md), [Google ğŸ”](Topic_Google.md) | 2023-08-07 |
| [RT-2: New model translates vision and language into action](https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action) ğŸŸ¢ | Metaâ€™s Robotic Transformer 2 (RT-2) is a vision-language-action model that combines web-scale capabilities with robotic control. It effectively recognizes visual and language patterns, generalizes emergent skills, and successfully leverages web-based data to learn new skills. | [Robotics ğŸ¤–](Topic_Robotics.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Meta â™¾](Topic_Meta.md) | 2023-08-07 |
| [Bardâ€™s latest update: more features, languages and countries](https://blog.google/products/bard/google-bard-new-features-update-july-2023/) ğŸŸ¢ | Bard, a language model, has expanded its availability worldwide and now supports multiple languages. New features include the ability to listen to Bardâ€™s responses, customize the tone and style of its output, pin and rename past conversations, export Python code to Replit and Google Colab, share responses with others, and utilize images in prompts with the help of Google Lens integration. | [Text-to-speech ğŸ“¢](Topic_Text-to-speech.md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [AI for coding ğŸ‘¨â€ğŸ’»](Topic_AI_for_coding.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Google Gemini ğŸŒŒ](Topic_Google_Gemini.md), [Google ğŸ”](Topic_Google.md) | 2023-07-17 |
| [Shutterstock expands deal with OpenAI to build generative AI tools](https://techcrunch.com/2023/07/11/shutterstock-expands-deal-with-openai-to-build-generative-ai-tools/) ğŸŸ¢ | OpenAI and Shutterstock have announced a partnership where OpenAI will use Shutterstockâ€™s media library to train its AI models. In return, Shutterstock gains priority access to OpenAIâ€™s advanced image transformation tools. Shutterstock is also working towards becoming a leader in generative AI by collaborating with top AI companies and compensating artists for their contributions to training the AI. | [AI and copyright Â©ï¸](Topic_AI_and_copyright.md), [AI datasets ğŸ“Š](Topic_AI_datasets.md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2023-07-17 |
| [CMU Researchers Expand Ability of Robots To Learn From Videos](https://www.cs.cmu.edu/news/2023/VRB_robot_tasks) ğŸŸ¢ | CMU researchers have developed a new method for teaching robots household tasks by training them to observe videos of humans completing those tasks. This approach can improve robotsâ€™ performance in cooking and cleaning by allowing them to master 12 different actions. | [Robotics ğŸ¤–](Topic_Robotics.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-06-26 |
| [Introducing Voicebox: The first generative AI model for speech to generalize across tasks with state-of-the-art performance](https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/) ğŸŸ¢ | Meta AI has developed Voicebox, a new model that uses a Flow Matching model to train on large and diverse datasets, enabling it to generate high-quality synthesized speech without specific training. The model can match audio styles, read text passages in multiple languages, and edit speech segments within audio recordings. The research paper and audio samples are available, but the model and code remain private to prevent misuse. | [Text-to-speech ğŸ“¢](Topic_Text-to-speech.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Meta â™¾](Topic_Meta.md) | 2023-06-26 |
| [Pixar Used AI to Stoke the Flames in â€˜Elementalâ€™](https://www.wired.com/story/pixar-elemental-artificial-intelligence-flames/) ğŸŸ¢ | Pixar used neural style transfer and collaborated with Disney Research Studios to solve the challenge of capturing the ethereal nature of fire in their film â€œElementalâ€. This ML innovation saved production time and reduced costs. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-06-26 |
| [LangChain & Vector Databases in Production Course](https://learn.activeloop.ai/courses/langchain) ğŸŸ¢ | LangChainâ€™s free AI course, LangChain & Vector Databases in Production, offers 50+ lessons and 10+ projects that cover API integration, prompt engineering, and production use. It teaches how to use Deep Lake, a versatile vector database for AI data that includes text, images, videos, and multiple embeddings. Basic Python knowledge, Jupyter Notebooks understanding, and GitHub familiarity are prerequisites. The course is designed to make AI practical and accessible, tailored to both experienced devs and enthusiasts. | [LangChain and LlamaIndex ğŸ”—](Topic_LangChain_and_LlamaIndex.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-06-26 |
| [Google Lens can now search for skin conditions](https://techcrunch.com/2023/06/14/google-lens-can-now-search-for-skin-conditions/) ğŸŸ¢ | Google Lens now has a feature that can identify skin conditions and other physical maladies by analyzing uploaded images. The feature can be integrated with chatbots to provide accurate answers about objects in photos. | [AI in healthcare ğŸ¥](Topic_AI_in_healthcare.md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Google ğŸ”](Topic_Google.md) | 2023-06-20 |
| [Paul McCartney records Beatles song with help of AI](https://www.semafor.com/article/06/13/2023/paul-mccartney-beatles-song-ai) ğŸŸ¢ | Paul McCartney used AI technology to restore John Lennonâ€™s voice and record a Beatles song from a 1978 cassette tape labeled â€œFor Paul.â€ This collaboration showcases the potential of AI in music preservation and opens up new opportunities for artists and fans in the future. | [Text-to-speech ğŸ“¢](Topic_Text-to-speech.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-06-20 |
| [OpenAIâ€™s plans according to Sam Altman](https://website-754fwhahs-humanloopml.vercel.app/blog/open_ai_talk) ğŸŸ¢ | OpenAI plans to prioritize creating a cheaper and faster GPT-4, extending context windows, and releasing multimodality in 2024. However, they are currently limited by GPU shortages and are unable to make models millions of times bigger in the near future. The finetuning API will be extended to the latest models. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [GPT-4 and GPT-4 turbo ğŸš€](Topic_GPT-4_and_GPT-4_turbo.md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2023-06-06 |
| [Nvidia demo about speaking to AI game characters](https://www.theverge.com/2023/5/28/23740908/nvidia-ace-demo-voice-ai-npc-game-characters) ğŸŸ¢ | Nvidia showcases a powerful AI-powered demo of conversational AI for game characters that enhances realism and engages players, providing game developers a tool to improve their gamesâ€™ storytelling and overall engagement. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Text-to-speech ğŸ“¢](Topic_Text-to-speech.md), [Speech-to-text ğŸ¤](Topic_Speech-to-text.md) | 2023-06-06 |
| [Googleâ€™s new generative AI tool can jazz up product images](https://www.theverge.com/2023/5/23/23734129/google-product-studio-generative-ai-ads-merchant-center) ğŸŸ¢ | Googleâ€™s new Product Studio uses generative AI to help Shopping merchants customize product images and improve their ad campaigns, with integration into the Merchant Center for added convenience. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Google ğŸ”](Topic_Google.md) | 2023-05-29 |
| [Stability AI releases StableStudio in latest push for open-source AI](https://www.theverge.com/2023/5/17/23726751/stability-ai-stablestudio-dreamstudio-stable-diffusion-artificial-intelligence) ğŸŸ¢ | Stability AI has launched StableStudio as part of its open-source AI efforts. StableStudio is a new open-source variant of its DreamStudio AI text-to-image web app. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Stable Diffusion ğŸ¨](Topic_Stable_Diffusion.md), [Stability AI âš–ï¸](Topic_Stability_AI.md) | 2023-05-22 |
| [Meta open-sources multisensory AI model that combines six types of data](https://www.theverge.com/2023/5/9/23716558/meta-imagebind-open-source-multisensory-modal-ai-model-research) ğŸŸ¢ | Meta has unveiled ImageBind, an open-source AI model indexing six data types (visual, audio, text, thermal, depth, movement) for multisensory AI. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Meta â™¾](Topic_Meta.md) | 2023-05-16 |
| [Artificial Intelligence Radio](https://artificialintelligenceradio.com/) ğŸŸ¢ | A web radio with AI-generated music. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-05-02 |
| [With Bedrock, Amazon enters the generative AI race](https://techcrunch.com/2023/04/13/with-bedrock-amazon-enters-the-generative-ai-race/) ğŸŸ¢ | Amazon Bedrock facilitates building AI-powered apps with pre-trained models from startups and AWS through an API to generate images, logos, and graphics. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Amazon ğŸŒ³](Topic_Amazon.md) | 2023-04-17 |
| [Meta introduced Segment Anything: Working toward the first foundation model for image segmentation](https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/) ğŸŸ¢ | Introducing Segment Anything: democratizing image segmentation with SAM â€” a versatile, promptable model trained on a versatile dataset under Apache 2.0. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Model release ğŸ‰](Topic_Model_release.md), [Meta â™¾](Topic_Meta.md) | 2023-04-11 |
| [The AI-powered storytelling format](https://beta.tome.app/) ğŸŸ¢ | Tome is an AI-powered storytelling platform that allows users to explain complex topics using narration and embeds from other sources. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-03-27 |
| [Gen-2 by Runway](https://research.runwayml.com/gen2) ğŸŸ¢ | Gen-2 by Runway is an AI tool that can synthesize new videos using only an image, text prompt, or words without needing a camera or lights. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-03-27 |
| [GPT-4 is out](https://openai.com/product/gpt-4) ğŸŸ¢ | GPT-4 is multimodal and accepts also images as inputs. It can handle over 25,000 words of text. GPT-4 can be tested with ChatGPT Plus. Otherwise, thereâ€™s an API waitlist. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [GPT-4 and GPT-4 turbo ğŸš€](Topic_GPT-4_and_GPT-4_turbo.md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2023-03-20 |
| [MuAViC: The first audio-video speech translation benchmark](https://ai.facebook.com/blog/muavic-audio-visual-speech-translation-benchmark/) ğŸŸ¢ | Using visual information to improve performance for English speech recognition tasks. | [Speech-to-text ğŸ¤](Topic_Speech-to-text.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-03-13 |
| [YouTubeâ€™s new leader teases AI tools that can virtually swap creatorsâ€™ outfits and locations](https://www.theverge.com/2023/3/1/23620143/youtube-ai-tool-features-ceo-neal-mohan-google-alphabet) ğŸŸ¢ |  | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-03-06 |
| [Could Stable Diffusion Solve a Gap in Medical Imaging Data?](https://hai.stanford.edu/news/could-stable-diffusion-solve-gap-medical-imaging-data) ğŸŸ¢ | Stanford scholars found a way to generate synthetic chest X-rays by fine-tuning the open-source Stable Diffusion foundation model. | [AI in healthcare ğŸ¥](Topic_AI_in_healthcare.md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Stable Diffusion ğŸ¨](Topic_Stable_Diffusion.md), [Stability AI âš–ï¸](Topic_Stability_AI.md) | 2023-02-20 |
| [Zero-shot image-to-text generation with BLIP-2](https://huggingface.co/blog/blip-2) ğŸŸ¢ | The guide introduces BLIP-2 from Salesforce Research which enables a suite of state-of-the-art visual-language models that are now available in Hugging Face Transformers. | [Hugging Face ğŸ¤—](Topic_Hugging_Face.md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-02-20 |
| [Hugging Face releases SpeechT5](https://huggingface.co/blog/speecht5) ğŸŸ¢ | a model able to do speech-to-text, text-to-speech, and speech-to-speech. | [Hugging Face ğŸ¤—](Topic_Hugging_Face.md), [Text-to-speech ğŸ“¢](Topic_Text-to-speech.md), [Speech-to-text ğŸ¤](Topic_Speech-to-text.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Model release ğŸ‰](Topic_Model_release.md) | 2023-02-13 |
| [Runway new product Gen-1](https://research.runwayml.com/gen1) ğŸŸ¢ | uses words and images to generate new videos out of existing ones. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-02-13 |
| [Dreamix: Video Diffusion Models are General Video Editors](https://dreamix-video-editing.github.io/) ğŸŸ¢ |  | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-02-13 |
| [OpenAI has ramped up its hiring around the world](https://www.semafor.com/article/01/27/2023/openai-has-hired-an-army-of-contractors-to-make-basic-coding-obsolete) ğŸŸ¢ | bringing on roughly 1,000 remote contractors over the past six months to create massive sets of images and audio clips to train AI tools. 60% of the contractors do data labeling and 40% are computer programmers. | [AI datasets ğŸ“Š](Topic_AI_datasets.md), [AI for coding ğŸ‘¨â€ğŸ’»](Topic_AI_for_coding.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2023-02-06 |
| [Noise2Music](https://noise2music.github.io/) ğŸŸ¢ | a series of diffusion models trained to generate high-quality 30-second music clips from text prompts. The generated audio is able to faithfully reflect key elements of the text prompt such as genre, tempo, instruments, mood and era. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-02-06 |
| [Trends in AI in 2023](https://towardsai.net/p/l/trends-in-ai%E2%80%8A-%E2%80%8A2023-round-up) ğŸŸ¢ | Predictions on language models, reinforcement learning, robotics, computer visionâ€¦ | [Reinforcement learning ğŸ®](Topic_Reinforcement_learning.md), [Robotics ğŸ¤–](Topic_Robotics.md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-02-06 |
| [Shutterstock has rolled out a generative AI toolkit](https://techcrunch.com/2023/01/25/after-inking-its-openai-deal-shutterstock-rolls-out-a-generative-ai-toolkit-to-create-images-based-on-text-prompts/) ğŸ”´ | to create images based on text prompts, while Getty Images is currently embroiled in a lawsuit against Stability AI. | [AI and copyright Â©ï¸](Topic_AI_and_copyright.md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [Stability AI âš–ï¸](Topic_Stability_AI.md) | 2023-01-30 |
| [Introducing Karlo, an Open Source DALL-E 2 (unCLIP)](https://huggingface.co/kakaobrain/karlo-v1-alpha)  | Karlo is a text-conditional image generation model based on OpenAIâ€™s unCLIP architecture with the improvement over the standard super-resolution model from 64px to 256px, recovering high-frequency details only in the small number of denoising steps. | [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2023-01-23 |