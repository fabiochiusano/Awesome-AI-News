# AI Chips and GPUs news

| Title | Summary | Topics | Week |
| --- | --- | --- | --- |
| [Nvidia shipped 3.76M data center GPUs in 2023 â€” dominates business with 98% revenue share](https://www.tomshardware.com/tech-industry/nvidia-shipped-376m-data-center-gpus-in-2023-dominates-business-with-98-revenue-share) ğŸŸ¢ | In 2023, Nvidia consolidated its position in the data center GPU market with a 98% share by distributing 3.76 million units and achieved a remarkable 126% revenue increase since 2020, reaching $60.9 billion, even amidst U.S. export restrictions and manufacturing hurdles. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-06-17 |
| [AMD unveils new AI chips to compete with Nvidia](https://www.fastcompany.com/91134766/amd-unveils-new-ai-chips-to-compete-with-nvidia) ğŸŸ¢ | AMD is challenging Nvidiaâ€™s leadership in AI with upcoming releases: the MI325X in 2024, and the MI350/MI400 series in 2025â€“2026, promising notable performance boosts to satisfy increasing AI demands. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-06-10 |
| [China invests $47 billion in largest ever chip fund](https://techxplore.com/news/2024-05-china-invests-billion-largest-chip.html) ğŸŸ¢ | China allocated $47.48 billion to a new chip fund aimed at advancing domestic semiconductor production, a critical step toward self-sufficiency and competitiveness in technology sectors, including AI. | [Funding ğŸ’°](Topic_Funding.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-06-03 |
| [Nvidia Stock Surges as Sales Forecast Delivers on AI Hopes](https://finance.yahoo.com/news/nvidia-forecast-shatters-estimates-ai-210754051.html) ğŸŸ¢ | Nvidiaâ€™s stock surged 9.3% after a promising sales forecast, pointing to a robust demand for AI technologies. The $28 billion projected Q2 revenue exceeds expectations, highlighting the companyâ€™s strong position in the AI market, buoyed by their new Blackwell chips and significant data-center revenue. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-05-27 |
| [Microsoft introduces Phi-Silica, a 3.3B parameter model made for Copilot+ PC NPUs](https://venturebeat.com/ai/microsoft-introduces-phi-silica-a-3-3b-parameter-model-made-for-copilot-pc-npus/) ğŸŸ¢ | Microsoft has unveiled Phi-Silica, a compact language model with 3.3 billion parameters, tailored for Copilot+ PCs equipped with NPUs. This model is engineered for rapid on-device inferencing, improving productivity and accessibility for Windows users with optimal power efficiency. Phi-Silica is Microsoftâ€™s inaugural local language model, with a release slated for June. | [Model release ğŸ‰](Topic_Model_release.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Microsoft ğŸªŸ](Topic_Microsoft.md) | 2024-05-27 |
| [100 things Google announced at I/O 2024](https://blog.google/technology/ai/google-io-2024-100-announcements/) ğŸŸ¢ | At Google I/O 2024, notable AI developments were announced such as Gemini 1.5 models, Trillium TPU, and enhanced AI in Google Search. Key introductions include Imagen 3 for image creation, Veo for video generation, and upgraded features in the Gemini app for premium users, alongside new generative media tools. | [Google Gemini ğŸŒŒ](Topic_Google_Gemini.md), [Google ğŸ”](Topic_Google.md), [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [AI for images ğŸ–¼ï¸](Topic_AI_for_images.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-05-21 |
| [Hugging Face is sharing $10 million worth of compute to help beat the big AI companies](https://www.theverge.com/2024/5/16/24156755/hugging-face-celement-delangue-free-shared-gpus-ai) ğŸŸ¢ | Hugging Face is dedicating $10M in free GPU resources to support AI developers, startups, and academics. Their ZeroGPU initiative, part of Hugging Face Spaces, offers communal GPU access, aiming to reduce computational access barriers and improve cost-efficiency. | [Hugging Face ğŸ¤—](Topic_Hugging_Face.md), [Funding ğŸ’°](Topic_Funding.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-05-21 |
| [Googleâ€™s new chips look to challenge Nvidia, Microsoft and Amazon](https://qz.com/google-ai-chip-nvidia-axion-arm-microsoft-1851397201) ğŸŸ¢ | Google has unveiled the Cloud TPU v5p, an AI chip that delivers nearly triple the training speed of its predecessor, the TPU v4, reinforcing its position in AI services and hardware. At the Google Cloud Next event, CEO Pichai highlighted the companyâ€™s AI advancements and collaborations, including the use of the A3 supercomputer and Blackwell chips in the AI Hypercomputer. Additionally, Google introduced the Google Axion CPU, an Arm-based processor that competes with similar offerings from Microsoft and Amazon, boasting a 30% performance improvement and better energy efficiency. | [Amazon ğŸŒ³](Topic_Amazon.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Google ğŸ”](Topic_Google.md), [Microsoft ğŸªŸ](Topic_Microsoft.md) | 2024-04-23 |
| [Lambda Announces $500M GPU-Backed Facility to Expand Cloud for AI](https://www.businesswire.com/news/home/20240402148086/en/Lambda-Announces-500M-GPU-Backed-Facility-to-Expand-Cloud-for-AI) ğŸŸ¢ | Lambda has successfully secured $500 million in funding to enhance its AI-oriented cloud services, powered by NVIDIA GPUs, following a Series C investment round. | [Funding ğŸ’°](Topic_Funding.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-04-08 |
| [OpenAI and Microsoft reportedly planning $100 billion datacenter project for an AI supercomputer](https://www.tomshardware.com/tech-industry/artificial-intelligence/openai-and-microsoft-reportedly-planning-dollar100-billion-datacenter-project-for-an-ai-supercomputer) ğŸŸ¢ | Microsoft and OpenAI have announced a partnership to construct â€œStargate,â€ an advanced AI supercomputer in the U.S., featuring millions of GPUs. The project, which may exceed $115 billion, represents a major commitment to expanding datacenter capabilities to advance AI research and development. | [Funding ğŸ’°](Topic_Funding.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Microsoft ğŸªŸ](Topic_Microsoft.md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2024-04-02 |
| [Amazon and Anthropic deepen their shared commitment to advancing generative AI](https://www.aboutamazon.com/news/company-news/amazon-anthropic-ai-investment) ğŸŸ¢ | Amazon has invested $4 billion in AI company Anthropic to further develop AI technologies. Anthropic leverages Amazon Web Services (AWS) Trainium and Inferentia chips for enhancing their AI models. Notably, Anthropicâ€™s Claude 3 models have been incorporated into Amazon Bedrock by AWS. | [Amazon ğŸŒ³](Topic_Amazon.md), [Funding ğŸ’°](Topic_Funding.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Claude ğŸ–‹ï¸](Topic_Claude.md), [Anthropic ğŸŒ](Topic_Anthropic.md) | 2024-04-02 |
| [â€˜We Created a Processor for the Generative AI Era,â€™ NVIDIA CEO Says](https://blogs.nvidia.com/blog/2024-gtc-keynote/) ğŸŸ¢ | NVIDIA CEO Jensen Huang announced the NVIDIA Blackwell computing platform at the GTC conference, aimed at advancing generative AI with superior training and inference capabilities. The platform includes enhanced interconnects for better performance and scalability. NVIDIA also launched NIM microservices for tailored AI deployment and Omniverse Cloud APIs for sophisticated simulation, signaling a transformative impact on sectors like healthcare and robotics. | [AI in healthcare ğŸ¥](Topic_AI_in_healthcare.md), [Robotics ğŸ¤–](Topic_Robotics.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-03-25 |
| [Nvidiaâ€™s data center GPU sales grow by a stunning 409% on huge demand for AI chips](https://siliconangle.com/2024/02/21/nvidias-data-center-gpu-sales-grow-stunning-409-huge-demand-ai-chips/) ğŸŸ¢ | Nvidia has experienced a significant surge in GPU sales, reporting a 409% increase due in large part to the rising demand for AI technologies. With Q4 earnings and revenue significantly outpacing Wall Street forecasts, the companyâ€™s financials have thrived on the back of robust sales from their Hopper GPU series, including the H100. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-02-26 |
| [GPU cloud company Together AI to raise $100m](https://www.datacenterdynamics.com/en/news/together-ai-set-to-receive-100m-in-funding-round-led-by-salesforce-ventures/) ğŸŸ¢ | Together AI, a GPU cloud company specializing in open-source AI tools and Nvidia server chip access, is nearing a $100 million funding round led by Salesforce Ventures, potentially elevating its valuation to $1 billion. | [Funding ğŸ’°](Topic_Funding.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-02-19 |
| [OpenAIâ€™s CEO Sam Altman is chasing trillions of dollars as investments to disrupt AI, chip industries](https://www.firstpost.com/tech/openai-sam-altman-is-chasing-trillions-of-dollars-as-investments-to-disrupt-ai-chip-industries-13708732.html) ğŸŸ¢ | Sam Altman, CEO of OpenAI, is actively seeking to secure $5â€“7 trillion in funding to expand the semiconductor industry to support AI development. This investment aims to address GPU shortages and foster the growth of both AI and artificial general intelligence. Altman is engaging with various stakeholders, including government officials from the UAE and the US, investors, and chip manufacturers, in his efforts to build a robust global chip-making infrastructure that meets the increasing demands and energy requirements of AI facilities. | [Funding ğŸ’°](Topic_Funding.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2024-02-12 |
| [OpenAIâ€™s Sam Altman Is Raising Money to Set Up AI Chip Factories](https://beebom.com/openai-sam-altman-raising-money-ai-chip-factories/) ğŸŸ¢ | OpenAI CEO Sam Altman is actively seeking investment, potentially over $8 billion, from entities including G42 and SoftBank to establish AI chip factories aimed at meeting the surging demand for specialized processors in the growing AI industry. | [Funding ğŸ’°](Topic_Funding.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2024-01-29 |
| [Hugging Face and Google partner for open AI collaboration](https://huggingface.co/blog/gcp-partnership) ğŸŸ¢ | Hugging Face has partnered with Google Cloud, providing users with access to enhanced AI models and integration with Google Cloud services like GKE and Vertex AI, utilizing Google TPUs and NVIDIA H100 GPUs. | [Hugging Face ğŸ¤—](Topic_Hugging_Face.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Google ğŸ”](Topic_Google.md) | 2024-01-29 |
| [Mark Zuckerberg indicates Meta is spending billions of dollars on Nvidia AI chips](https://www.cnbc.com/2024/01/18/mark-zuckerberg-indicates-meta-is-spending-billions-on-nvidia-ai-chips.html) ğŸŸ¢ | Meta plans a significant investment in AI research by integrating 350,000 Nvidia H100 GPUs by 2024. Given their high cost â€” estimated between $25K-$30K â€” this investment underlines Metaâ€™s commitment to scaling up computing power. Overall, Metaâ€™s strategy to amass the computational equivalent of 600K H100 GPUs highlights a substantial push to enhance its AI capabilities. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Meta â™¾](Topic_Meta.md) | 2024-01-22 |
| [Cristiano Amon: generative AI is â€˜evolving very, very fastâ€™ into mobile devices](https://www.ft.com/content/dbc0984b-4801-4aeb-bcab-480704c34161) ğŸŸ¢ | Qualcomm CEO Cristiano Amon envisions generative AI rapidly integrating into mobiles, PCs, and cars, aiming to offer enriched user experiences by complementing cloud AI. Leveraging Qualcommâ€™s efficient AI processors, these advancements are set to facilitate real-time AI applications on battery- operated devices, proactively meeting user needs. | [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2024-01-08 |
| [Introducing gigaGPT: GPT-3 sized models in 565 lines of code](https://www.cerebras.net/blog/introducing-gigagpt-gpt-3-sized-models-in-565-lines-of-code) ğŸŸ¢ | Cerebras has released gigaGPT, a model implementation similar to nanoGPT but with over 100 billion parameters. By leveraging Cerebras hardware and different optimizers, gigaGPT overcomes the limitations of GPU memory and the need for complex scaling frameworks, offering a simplified approach for training large models. | [Model release ğŸ‰](Topic_Model_release.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [GPT-3, GPT-3.5, and GPT-3.5 turbo ğŸ’¡](Topic_GPT-3_GPT-3.5_and_GPT-3.5_turbo.md) | 2023-12-19 |
| [Nvidia unveils H200, its newest high-end chip for training AI models](https://www.cnbc.com/2023/11/13/nvidia-unveils-h200-its-newest-high-end-chip-for-training-ai-models.html) ğŸŸ¢ | Nvidia introduces the H200 GPU, an upgraded version with 141GB of high-bandwidth memory. This enhancement helps with the inference process in training large AI models. Set to be released in Q2 2024, the H200 will compete with AMDâ€™s MI300X GPU, which also offers increased memory capacity for handling big models. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-11-20 |
| [NVIDIA makes Pandas much faster leveraging GPUs](https://rapids.ai/cudf-pandas/) ğŸŸ¢ | NVIDIA has significantly enhanced the Pandas library, achieving up to 150 times faster performance by capitalizing on GPUs. With the new cudf.pandas module, operations are seamlessly executed on either the GPU or CPU, providing automatic synchronization and efficient switching between the two. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-11-13 |
| [New AWS service lets customers rent Nvidia GPUs for quick AI projects](https://techcrunch.com/2023/11/01/new-aws-service-lets-customers-rent-nvidia-gpus-for-quick-ai-projects/) ğŸŸ¢ | AWS has introduced Amazon Elastic Compute Cloud (EC2) Capacity Blocks for ML, enabling AI practitioners to reserve Nvidia GPUs for specific time periods. This new service grants access to Nvidia H100 Tensor Core GPU instances, allowing users to reserve instances for up to 14 days ahead of time, with shutdowns scheduled automatically. | [Amazon ğŸŒ³](Topic_Amazon.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-11-13 |
| [New AWS service lets customers rent Nvidia GPUs for quick AI projects](https://techcrunch.com/2023/11/01/new-aws-service-lets-customers-rent-nvidia-gpus-for-quick-ai-projects/) ğŸŸ¢ | AWS launches Amazon Elastic Compute Cloud (EC2) Capacity Blocks for ML, allowing customers to rent Nvidia GPUs for specific time frames. | [Amazon ğŸŒ³](Topic_Amazon.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-11-06 |
| [Microsoft to Unveil In-House AI Chip, Reducing Reliance on NVIDIA](https://www.maginative.com/article/microsoft-to-unveil-in-house-ai-chip-reducing-reliance-on-nvidia/) ğŸ”´ | Microsoft is soon launching its own AI chip called Athena, aiming to reduce reliance on NVIDIA GPUs and compete against NVIDIAâ€™s H100 GPU for AI acceleration in data centers. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Microsoft ğŸªŸ](Topic_Microsoft.md) | 2023-10-10 |
| [OpenAI is exploring making its own AI chips](https://www.businessinsider.com/openai-is-considering-making-its-own-ai-chips-chatgpt-2023-10) ğŸŸ¢ | OpenAI is considering developing its own AI chips for ChatGPT due to a global shortage of processors for training AI models. This move could help reduce the high operating costs of ChatGPT, which currently amount to $700,000 per day. OpenAIâ€™s decision may diverge from Microsoft, their partner, who is also working on their own AI chips. | [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Microsoft ğŸªŸ](Topic_Microsoft.md), [ChatGPT ğŸ’¬](Topic_ChatGPT.md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2023-10-10 |
| [Introducing Stable LM 3B: Bringing Sustainable, High-Performance Language Models to Smart Devices](https://stability.ai/blog/stable-lm-3b-sustainable-high-performance-language-models-smart-devices) ğŸŸ¢ | Stability AI introduces Stable LM 3B, a high-performing language model designed for smart devices. With 3 billion parameters, it outperforms state-of-the-art 3B models and reduces operating costs and power consumption. The model enables a wider range of applications on smart devices, PCs, and edge computing. | [Stability AI âš–ï¸](Topic_Stability_AI.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-10-10 |
| [Amazon will invest up to $4 billion in Anthropic](https://www.anthropic.com/index/anthropic-amazon) ğŸŸ¢ | Amazon has made a significant $4 billion investment in Anthropic. This partnership will enable Anthropic to benefit from Amazon Web Services (AWS), specifically leveraging AWSâ€™s Trainium and Inferentia chips to enhance model training and deployment capabilities. Additionally, Anthropic will use Amazon Bedrock to optimize Claude versions and explore finetuning options. | [Amazon ğŸŒ³](Topic_Amazon.md), [Funding ğŸ’°](Topic_Funding.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Claude ğŸ–‹ï¸](Topic_Claude.md), [Anthropic ğŸŒ](Topic_Anthropic.md) | 2023-10-02 |
| [LLM Startup Embraces AMD GPUs, Says ROCm Has â€˜Parityâ€™ With Nvidiaâ€™s CUDA Platform](https://www.crn.com/news/components-peripherals/llm-startup-embraces-amd-gpus-says-rocm-has-parity-with-nvidia-s-cuda-platform) ğŸŸ¢ | A startup called Lamini is using over 100 AMD Instinct MI200 GPUs and found that AMDâ€™s ROCm software platform rivals Nvidiaâ€™s CUDA platform. They claim that running a large language model on their platform is 10x cheaper than on Amazon Web Services. | [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [NVIDIA ğŸ®](Topic_NVIDIA.md) | 2023-10-02 |
| [NVIDIA and Hugging Face to Connect Millions of Developers to Generative AI Supercomputing](https://nvidianews.nvidia.com/news/nvidia-and-hugging-face-to-connect-millions-of-developers-to-generative-ai-supercomputing) ğŸŸ¢ | NVIDIA and Hugging Face have partnered to offer AI developers access to high-performance GPUs for deep learning through DGX Cloud integration. | [Hugging Face ğŸ¤—](Topic_Hugging_Face.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-08-14 |
| [Cerebras Systems signs $100 million AI supercomputer deal with UAEâ€™s G42](https://www.reuters.com/technology/cerebras-systems-signs-100-mln-ai-supercomputer-deal-with-uaes-g42-2023-07-20/) ğŸŸ¢ | Cerebras Systems has struck a $100 million deal with G42, marking the debut of AI supercomputers that could potentially challenge Nvidiaâ€™s market position. In response to chip shortages, cloud computing providers are seeking alternative solutions. To accelerate the rollout, Cerebras will construct three Condor Galaxy systems in the United States, with the first supercomputer set to go online this year, followed by two others in early 2024. | [Funding ğŸ’°](Topic_Funding.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-07-24 |
| [Nvidia deepens bets on AI in drug discovery with Recursion investment](https://www.reuters.com/technology/nvidia-invests-50-mln-recursion-train-ai-models-drug-discovery-2023-07-12/) ğŸŸ¢ | Nvidia invests $50M in Recursion, a biotech company using AI to revolutionize drug discovery. This partnership allows Recursion to utilize Nvidiaâ€™s platform and access their advanced AI technology. Recursionâ€™s share price surged by 83% post-announcement, highlighting the marketâ€™s recognition of AIâ€™s significance in drug discovery. | [AI in healthcare ğŸ¥](Topic_AI_in_healthcare.md), [Funding ğŸ’°](Topic_Funding.md), [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-07-17 |
| [Miner Pivots 38,000 GPUs From Crypto to AI](https://www.tomshardware.com/news/hive-blockchain-pivoting-to-ai) ğŸŸ¢ | Cryptomining firm Hive Blockchain is redirecting their efforts from Ethereum mining to AI workloads. With 38,000 GPUs at their disposal, they aim to generate revenue while still utilizing some GPU power for crypto mining. However, transitioning to AI compute poses challenges as older ETH mining GPUs have limited value in this market. | [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-07-10 |
| [Inside Chinaâ€™s underground market for high-end Nvidia AI chips](https://www.reuters.com/technology/inside-chinas-underground-market-high-end-nvidia-ai-chips-2023-06-19/) ğŸ”´ | Despite U.S. export restrictions, Chinese demand for high-end Nvidia AI chips remains strong and vendors in Shenzhen and Hong Kong have emerged to offer them at steep prices in a de facto underground market. The exact volume of chip flow is unknown, but local authorities are also reported to be buyers. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [AI regulation ğŸ“œ](Topic_AI_regulation.md) | 2023-06-26 |
| [Chinaâ€™s ByteDance Has Gobbled Up $1 Billion of Nvidia GPUs for AI This Year](https://www.tomshardware.com/news/chinas-bytedance-has-gobbled-up-dollar1-billion-of-nvidia-gpus-for-ai-this-year) ğŸŸ¢ | Chinese tech giant ByteDance has reportedly invested $1 billion in Nvidiaâ€™s HPC products, including the A100 and H800 cards, totaling about 100,000 units, to fulfill the high demand for AI technology. China recognizes the impact of AI on the global market and has embraced it, investing heavily in HPC hardware. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-06-26 |
| [OpenAIâ€™s plans according to Sam Altman](https://website-754fwhahs-humanloopml.vercel.app/blog/open_ai_talk) ğŸŸ¢ | OpenAI plans to prioritize creating a cheaper and faster GPT-4, extending context windows, and releasing multimodality in 2024. However, they are currently limited by GPU shortages and are unable to make models millions of times bigger in the near future. The finetuning API will be extended to the latest models. | [Multimodal AI (image, video, audio) ğŸ“¸](Topic_Multimodal_AI_(image_video_audio).md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [GPT-4 and GPT-4 turbo ğŸš€](Topic_GPT-4_and_GPT-4_turbo.md), [OpenAI ğŸŒŸ](Topic_OpenAI.md) | 2023-06-06 |
| [Why Nvidia is suddenly one of the most valuable companies in the world](https://www.washingtonpost.com/technology/2023/05/25/nvidia-ai-stock-gpu-chatbots/) ğŸŸ¢ | NVIDIAâ€™s GPUs have become a crucial component in developing AI, leading its worth to $939.3 billion; with AI applications requiring huge amounts of data, companies are buying thousands of NVIDIAâ€™s expensive chips. NVIDIAâ€™s dominance in the industry is predicted to persist as startups compete with big tech for access to its costly GPUs. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-06-06 |
| [Intel Announces Aurora genAI, Generative AI Model With 1 Trillion Parameters](https://wccftech.com/intel-aurora-genai-chatgpt-competitor-generative-ai-model-with-1-trillion-parameters/) ğŸŸ¢ | Intel has announced the Aurora genAI model, with 1 trillion parameters, which will be trained on scientific texts and structured scientific data to target cancer research, systems biology, cosmology, polymer chemistry, materials, and climate science. It will be powered by the Aurora supercomputer and has potential to suggest experiments and accelerate drug design targets. | [AI in healthcare ğŸ¥](Topic_AI_in_healthcare.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-05-29 |
| [Meta bets big on AI with custom chips and a supercomputer](https://techcrunch.com/2023/05/18/meta-bets-big-on-ai-with-custom-chips-and-a-supercomputer/) ğŸŸ¢ | Meta lifted the curtains on its efforts to develop in-house infrastructure for AI workloads, including generative AI. | [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Meta â™¾](Topic_Meta.md) | 2023-05-22 |
| [Microsoft Readies AI Chip as Machine Learning Costs Surge](https://www.theinformation.com/articles/microsoft-readies-ai-chip-as-machine-learning-costs-surge) ğŸŸ¢ | Microsoft creating Athena chip for AIâ€™s large-language models, aiming to save money and time. Amazon, Google & Facebook are creating their own AI chips too. | [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Microsoft ğŸªŸ](Topic_Microsoft.md) | 2023-04-24 |
| [Elon Musk is moving forward with a new generative-AI project at Twitter after purchasing thousands of GPUs](https://www.businessinsider.com/elon-musk-twitter-investment-generative-ai-project-2023-4) ğŸŸ¢ | Elon Musk is pursuing a Twitter AI project with a large language model despite recently calling to halt AI training. | [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md) | 2023-04-17 |
| [Microsoft spent hundreds of millions of dollars on a ChatGPT supercomputer](https://www.theverge.com/2023/3/13/23637675/microsoft-chatgpt-bing-millions-dollars-supercomputer-openai) ğŸŸ¢ | Microsoft says it connected tens of thousands of Nvidia A100 chips and reworked server racks to build the hardware behind ChatGPT and its own Bing AI bot. | [NVIDIA ğŸ®](Topic_NVIDIA.md), [AI Chips and GPUs ğŸ–¥ï¸](Topic_AI_Chips_and_GPUs.md), [Microsoft ğŸªŸ](Topic_Microsoft.md), [ChatGPT ğŸ’¬](Topic_ChatGPT.md) | 2023-03-20 |